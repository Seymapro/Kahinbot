{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline for [Human Pin Code](https://humanpincode.com/) by *Douglas Forbes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook outlines a data processing pipeline designed to extract, convert, and summarize content from Douglas Forbes' book, \"Human Pin Code\". The goal is to prepare the book's content, specifically the sections related to individual \"pin code\" digits, for further analysis or use with large language models (LLMs).\n",
    "\n",
    "The pipeline consists of three main stages:\n",
    "\n",
    "1.  **Stage 0: Preparations:** Initializes constants, directory paths, and sets up the Google Gemini API client and configuration for subsequent tasks (Markdown conversion and summarization). Includes helper functions for uploading files to Gemini and waiting for them to become active.\n",
    "2.  **Stage 1: Partition the book by its chapters and digits:** Uses the `pymupdf` library to open the main PDF book and partition it into smaller PDF files. Each partition corresponds to a specific chapter or \"digit\" section of the book, based on predefined page ranges. This step is crucial for breaking down the large document into manageable chunks relevant to specific topics (digits).\n",
    "3.  **Stage 2: Convert PDF partitions to Markdown files:** Iterates through the partitioned PDF files. For each PDF, it uploads the file to the Google Gemini API, prompts the model to convert the PDF content into Markdown format using a specialized configuration (`md_content_config`), and saves the resulting Markdown text to a new file. This converts the content into a more easily parsable text format.\n",
    "4.  **Stage 3: Summarization:** Processes the generated Markdown files. It combines the \"initial\" section of a chapter with the specific \"digit\" section's content. This combined text is then sent to the Google Gemini API with a summarization configuration (`summ_content_config`) designed to create a Turkish bulleted list summary of the key concepts related to that digit. The resulting summary is saved to a new Markdown file.\n",
    "\n",
    "The overall process aims to transform the structured information within the PDF book into summarized, text-based content, organized by the book's internal structure (chapters/digits), making it suitable for downstream applications like knowledge bases or further LLM processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import pymupdf\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from io import IOBase\n",
    "    from os import PathLike\n",
    "    from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0: Preparations\n",
    "\n",
    "This initial stage involves setting up the necessary environment and resources for the data processing pipeline. It includes defining constants for directory paths and file names, establishing the connection to the Google Gemini API using an API key from environment variables, and implementing helper functions for managing file uploads to Gemini and monitoring their processing status. Additionally, specific configurations for the Gemini model are defined for the Markdown conversion and summarization tasks, including system instructions, temperature settings, response format, and safety settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DIR_TR = \"./tr\"\n",
    "PDF_TR = f\"{DIR_TR}/PDFs\"\n",
    "MD_TR = f\"{DIR_TR}/MDs\"\n",
    "SUMM_TR = f\"{DIR_TR}/Summarizations\"\n",
    "BOOK = \"./forbes_2002.pdf\"\n",
    "\n",
    "TIMEOUT_IN_SECONDS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini API client using environment variable\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gemini(file_path: \"str | Path | PathLike[str] | IOBase\", mime_type: str | None = None) -> types.File:\n",
    "    \"\"\"Upload a file to the Google Gemini API for processing.\n",
    "\n",
    "    This function takes a file path or file-like object and uploads it to the Gemini API.\n",
    "    The file can be used as input for various Gemini model tasks like content generation\n",
    "    or analysis.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the file or a file-like object to upload. Can be:\n",
    "            - A string path\n",
    "            - A pathlib.Path object\n",
    "            - A PathLike object\n",
    "            - An IOBase object (file handle)\n",
    "        mime_type: Optional MIME type of the file. If None, Gemini will attempt to\n",
    "            detect the type automatically.\n",
    "\n",
    "    Returns:\n",
    "        types.File: A Gemini File object representing the uploaded file.\n",
    "            Contains metadata like uri, name, and display_name.\n",
    "\n",
    "    Raises:\n",
    "        UploadError: If the file upload fails\n",
    "        ValueError: If the file path is invalid or file cannot be read\n",
    "        TypeError: If the mime_type is invalid\n",
    "\n",
    "    Example:\n",
    "        >>> file = upload_to_gemini(\"document.pdf\", mime_type=\"application/pdf\")\n",
    "        >>> print(f\"Uploaded {file.display_name} as {file.uri}\")\n",
    "\n",
    "    See Also:\n",
    "        - https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
    "    \"\"\"\n",
    "    file = client.files.upload(file=file_path, config=types.UploadFileConfig(mime_type=mime_type))\n",
    "\n",
    "    print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_file_active(file: types.File) -> None:\n",
    "    \"\"\"Waits for a Gemini API file to become active through polling.\n",
    "\n",
    "    Continuously monitors the processing state of a file uploaded to the Gemini API\n",
    "    until it becomes active or fails. Uses a simple polling approach with fixed\n",
    "    intervals defined by TIMEOUT_IN_SECONDS.\n",
    "\n",
    "    Args:\n",
    "        file: A Gemini API File object returned from the upload operation. Must contain\n",
    "            a valid name attribute.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If file.name or file.state is None\n",
    "        Exception: If the file processing fails (final state is not \"ACTIVE\")\n",
    "        TypeError: If file is not a valid Gemini File object\n",
    "        ApiError: If there are issues communicating with the Gemini API\n",
    "\n",
    "    Notes:\n",
    "        - Prints status updates to console with dots indicating ongoing processing\n",
    "        - Current implementation uses basic polling - consider more robust approaches\n",
    "          for production use like exponential backoff or async polling\n",
    "        - Success/failure is determined solely by the final state being \"ACTIVE\"\n",
    "\n",
    "    Example:\n",
    "        >>> file = client.files.upload(file_path=\"document.pdf\")\n",
    "        >>> wait_for_file_active(file)  # Blocks until file is ready\n",
    "    \"\"\"\n",
    "    assert file.name is not None, \"File name should not be None\"\n",
    "\n",
    "    print(f\"Waiting for processing file {file.name}...\")\n",
    "\n",
    "    file = client.files.get(name=file.name)\n",
    "\n",
    "    while file.state.name == \"PROCESSING\":  # type: ignore[reportOptionalMemberAccess]\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "\n",
    "        time.sleep(TIMEOUT_IN_SECONDS)\n",
    "\n",
    "        file = client.files.get(name=file.name)  # type: ignore[reportArgumentType]\n",
    "\n",
    "    assert file.state is not None, \"File state should not be None\"\n",
    "\n",
    "    if file.state.name != \"ACTIVE\":\n",
    "        raise Exception(f\"File {file.name} failed to process\")\n",
    "\n",
    "    print(f\"File {file.name} is ready!\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_content_config = types.GenerateContentConfig(\n",
    "    system_instruction=\"\"\"You are a specialized Markdown converter designed to process and repair corrupted Turkish text files. Your task is to take potentially corrupted Turkish text, clean it, and convert it into well-formatted Markdown.  You should perform the following steps in order:\n",
    "\n",
    "1.  **Text Extraction and Preservation:**  Extract the complete text from the input.  Crucially, preserve the original character order and any unusual characters *even if they appear to be errors*.  Do not attempt to \"correct\" anything at this stage.\n",
    "\n",
    "2.  **De-hyphenation (Turkish-Specific):** Carefully de-hyphenate the raw text, paying close attention to Turkish hyphenation rules.  This involves:\n",
    "    *   Identifying hyphens at the end of lines.\n",
    "    *   Determining if the hyphen represents a true word break (requiring removal and joining of the word parts) or a hyphenated word (requiring the hyphen to be retained).  Use Turkish linguistic rules and context to make this determination. *Prioritize accurately joining words that were split across lines.*  Be conservative; if unsure, it's better to leave a hyphen than to incorrectly join unrelated words.\n",
    "\n",
    "3.  **Corruption Repair (Turkish-Specific):** This is the most complex step and requires a deep understanding of Turkish orthography and common OCR/scanning errors. Address the following types of corruption:\n",
    "    *   **Typos:** Correct common Turkish typographical errors, including incorrect characters, transpositions, and omissions. Use a Turkish spellchecker or language model (internally, if possible) to assist, but *prioritize corrections that are highly likely to be accurate*.  Avoid making speculative changes.\n",
    "    *   **Spacing Errors:**\n",
    "        *   **Missing Spaces:** Insert spaces between words where they are missing (e.g., \"kelimelerarasındaboşluk\").\n",
    "        *   **Extra Spaces:** Remove extraneous spaces within words (e.g., \"k e l i m e\") or between characters.\n",
    "        *   **Incorrect Spaces around Punctuation:** Ensure correct spacing around Turkish punctuation marks (periods, commas, question marks, etc.).\n",
    "    *   **Paragraph Reconstruction:**  Identify and correct incorrect paragraph breaks caused by page endings or scanning artifacts.  Use contextual clues (sentence structure, topic shifts) to determine true paragraph boundaries.  Combine fragments of sentences that were split across lines.\n",
    "    *   **Character Corruption:** Correct corrupted UTF-8 or other encoding issues. The goal is to correct the text to accurate Turkish spelling.\n",
    "\n",
    "4.  **Markdown Conversion:** Convert the cleaned and corrected Turkish text to Markdown, adhering to the following rules:\n",
    "    *   **Headings:**  Identify potential headings based on context and capitalization. Use appropriate Markdown heading levels (`#`, `##`, `###`, etc.).  Be conservative; if unsure, prefer a lower heading level or plain text.\n",
    "    *   **Lists:**  Identify and format bulleted or numbered lists. Look for common list indicators (e.g., numbers, bullets, dashes).\n",
    "    *   **Paragraphs:** Separate paragraphs with *two* newline characters (`\\n\\n`). This is crucial for proper Markdown rendering.\n",
    "    *   **Other Elements:** If you confidently identify other Markdown elements (e.g., bold, italics, blockquotes), format them appropriately. However, *prioritize accuracy over completeness*.  It's better to have plain text than incorrect Markdown.\n",
    "    * **Do not add any elements not supported in Markdown**\n",
    "\n",
    "5. **Output**\n",
    "    *   **Markdown Only:** Output *only* the resulting Markdown text. Do not include any explanations, comments, or additional information.\n",
    "    * **No additional changes:** Do not provide additional output.\"\"\",\n",
    "    temperature=0.1,\n",
    "    response_mime_type=\"text/plain\",\n",
    "    safety_settings=[\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_UNSPECIFIED, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_content_config = types.GenerateContentConfig(\n",
    "    system_instruction=\"\"\"You are a specialist in summarizing personality typing systems, particularly those similar to and including Douglas Forbes' \"Human Design System\" (often referred to as the \"Human Pin Code,\" though this isn't the official name).  Your task is to create a comprehensive summary of the provided text (which will be pasted below this prompt).  The summary should be in the form of a bulleted list.\n",
    "\n",
    "**Specific Instructions:**\n",
    "\n",
    "1.  **Target Audience:** Assume the reader has *some* familiarity with the general concept of personality typing (e.g., Myers-Briggs, Enneagram) but may be new to Forbes' system or similar concepts.\n",
    "2.  **Focus:** Identify and summarize the *key concepts, principles, and terminology* presented in the text.  Don't get bogged down in minor details; prioritize the core ideas.  If the text describes specific types, profiles, or categories, clearly outline their defining characteristics.\n",
    "3.  **Language:**  The summary must be written in **Turkish**.\n",
    "4.  **Format:** Use Markdown for the bulleted list. Each bullet point should be concise but informative.  Use nested bullet points (indentation) to show hierarchical relationships between concepts where appropriate.  For example, if a main concept has several sub-components, list the main concept as a top-level bullet and the sub-components as indented bullets beneath it.\n",
    "5.  **Comprehensiveness:** While concise, the summary should be comprehensive enough that someone reading it would gain a solid understanding of the main ideas presented in the original text. Avoid overly simplistic or vague summaries.\n",
    "6.  **Objectivity:** Maintain a neutral and objective tone.  Do not express personal opinions about the validity or usefulness of the system being described.  Present the information as it is presented in the text.\n",
    "7.  **Terminology:** Pay close attention to any specialized terminology used in the text.  If the Turkish translation of a term isn't immediately obvious, provide the English term in parentheses after the Turkish term the *first* time it appears.  (e.g., \"Enerji Tipi (Energy Type)\")\n",
    "8. **Contextualization (if applicable):** If the provided text refers to other personality systems or authors, briefly note these connections in the summary *if they are essential to understanding the main points*.\n",
    "\n",
    "**Example Structure (Markdown - Turkish):**\n",
    "\n",
    "```markdown\n",
    "- **Ana Kavram 1:** Kısa açıklama.\n",
    "    - Alt Kavram 1.1: Daha detaylı açıklama.\n",
    "    - Alt Kavram 1.2: Daha detaylı açıklama.\n",
    "- **Ana Kavram 2:** Kısa açıklama (İngilizce Terim).\n",
    "    - Alt Kavram 2.1: Daha detaylı açıklama.\n",
    "- **Ana Kavram 3:** ...\n",
    "```\n",
    "\n",
    "Do not provide additional output.\"\"\",\n",
    "    temperature=0.5,\n",
    "    response_mime_type=\"text/plain\",\n",
    "    safety_settings=[\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "        types.SafetySetting(\n",
    "            category=types.HarmCategory.HARM_CATEGORY_UNSPECIFIED, threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Partition the book by its chapters and digits\n",
    "\n",
    "This stage partitions the book \"Human Pin Code\" into smaller PDF files based on predefined page ranges for each chapter and its associated \"pin code\" digits. This process is essential for breaking down the large document into manageable, topic-specific chunks, which helps in providing large language models with focused content, thereby reducing the likelihood of generating inaccurate or irrelevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGITS_TO_PAGE_RANGE = {\n",
    "    1: {\n",
    "        \"initial\": (59, 61),\n",
    "        1: (61, 65),\n",
    "        2: (65, 67),\n",
    "        3: (67, 69),\n",
    "        4: (69, 71),\n",
    "        5: (71, 73),\n",
    "        6: (73, 76),\n",
    "        7: (76, 78),\n",
    "        8: (78, 80),\n",
    "        9: (80, 83),\n",
    "    },\n",
    "    2: {\n",
    "        \"initial\": (85, 87),\n",
    "        1: (87, 89),\n",
    "        2: (89, 91),\n",
    "        3: (91, 93),\n",
    "        4: (93, 96),\n",
    "        5: (98, 101),\n",
    "        6: (101, 103),\n",
    "        7: (103, 105),\n",
    "        8: (105, 107),\n",
    "        9: (107, 109),\n",
    "    },\n",
    "    3: {\n",
    "        \"initial\": (111, 112),\n",
    "        1: (112, 115),\n",
    "        2: (115, 117),\n",
    "        3: (117, 119),\n",
    "        4: (119, 122),\n",
    "        5: (122, 124),\n",
    "        6: (124, 126),\n",
    "        7: (126, 129),\n",
    "        8: (129, 131),\n",
    "        9: (131, 133),\n",
    "    },\n",
    "    4: {\n",
    "        \"initial\": (135, 136),\n",
    "        1: (136, 138),\n",
    "        2: (138, 140),\n",
    "        3: (140, 142),\n",
    "        4: (142, 144),\n",
    "        5: (144, 146),\n",
    "        6: (146, 148),\n",
    "        7: (148, 150),\n",
    "        8: (150, 152),\n",
    "        9: (152, 155),\n",
    "    },\n",
    "    5: {\n",
    "        \"initial\": (157, 159),\n",
    "        1: (159, 161),\n",
    "        2: (161, 163),\n",
    "        3: (163, 165),\n",
    "        4: (165, 167),\n",
    "        5: (167, 169),\n",
    "        6: (169, 171),\n",
    "        7: (171, 173),\n",
    "        8: (173, 175),\n",
    "        9: (175, 177),\n",
    "    },\n",
    "    6: {\n",
    "        \"initial\": (180, 182),\n",
    "        1: (182, 184),\n",
    "        2: (184, 186),\n",
    "        3: (186, 188),\n",
    "        4: (188, 191),\n",
    "        5: (191, 193),\n",
    "        6: (193, 195),\n",
    "        7: (195, 198),\n",
    "        8: (198, 201),\n",
    "        9: (201, 203),\n",
    "    },\n",
    "    7: {\n",
    "        \"initial\": (204, 205),\n",
    "        1: (205, 207),\n",
    "        2: (207, 209),\n",
    "        3: (209, 211),\n",
    "        4: (211, 213),\n",
    "        5: (213, 214),\n",
    "        6: (214, 216),\n",
    "        7: (216, 218),\n",
    "        8: (218, 220),\n",
    "        9: (220, 222),\n",
    "    },\n",
    "    8: {\n",
    "        \"initial\": (224, 226),\n",
    "        1: (226, 228),\n",
    "        2: (228, 230),\n",
    "        3: (230, 232),\n",
    "        4: (232, 234),\n",
    "        5: (234, 236),\n",
    "        6: (236, 238),\n",
    "        7: (238, 240),\n",
    "        8: (240, 242),\n",
    "        9: (242, 244),\n",
    "    },\n",
    "    9: {\n",
    "        \"initial\": (246, 247),\n",
    "        1: (247, 248),\n",
    "        2: (248, 249),\n",
    "        3: (249, 250),\n",
    "        4: (250, 251),\n",
    "        5: (251, 252),\n",
    "        6: (252, 253),\n",
    "        7: (253, 254),\n",
    "        8: (254, 255),\n",
    "        9: (255, 256),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymupdf.open(BOOK) as forbes_book:\n",
    "    for place, digits in DIGITS_TO_PAGE_RANGE.items():\n",
    "        for digit, (start, end) in digits.items():\n",
    "            with pymupdf.open() as part_pdf:\n",
    "                part_pdf.insert_pdf(forbes_book, from_page=start, to_page=end - 1)\n",
    "                part_pdf.save(f\"{PDF_TR}/{place}_{digit}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Convert PDF partitions to Markdown files\n",
    "\n",
    "Converting the partitioned PDF files into Markdown format facilitates easier text extraction and processing compared to binary PDF data. This step prepares the content for subsequent analysis or summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_md(pdf_path: str, md_path: str) -> None:\n",
    "    \"\"\"Converts a PDF file to Markdown format using the Google Gemini API.\n",
    "\n",
    "    This function takes a PDF file, uploads it to the Gemini API for processing,\n",
    "    and converts its content to Markdown format using a specialized configuration.\n",
    "    The resulting Markdown content is then saved to a new file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path: String path to the source PDF file to be converted.\n",
    "        md_path: String path where the resulting Markdown file should be saved.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the uploaded file name or response text is None.\n",
    "        FileNotFoundError: If the source PDF file doesn't exist or output path is invalid.\n",
    "        IOError: If there are issues reading the PDF or writing the Markdown file.\n",
    "        Exception: If the Gemini API request fails or returns an error.\n",
    "\n",
    "    Note:\n",
    "        - The function uses the global Gemini client and md_content_config for conversion\n",
    "        - The uploaded PDF file is automatically deleted from Gemini after conversion\n",
    "        - The function uses UTF-8 encoding when writing the output file\n",
    "        - Conversion quality depends on the PDF's text extraction quality\n",
    "\n",
    "    Example:\n",
    "        >>> pdf_to_md(\"chapter1.pdf\", \"chapter1.md\")\n",
    "        # Converts chapter1.pdf to Markdown and saves as chapter1.md\n",
    "    \"\"\"\n",
    "    file = upload_to_gemini(pdf_path, mime_type=\"application/pdf\")\n",
    "    wait_for_file_active(file)\n",
    "\n",
    "    assert file.name is not None, \"File name should not be None\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-preview-05-20\",\n",
    "        contents=[file, \"Convert this PDF file to Markdown.\"],\n",
    "        config=md_content_config,\n",
    "    )\n",
    "\n",
    "    client.files.delete(name=file.name)\n",
    "\n",
    "    assert response.text is not None, \"Response text should not be None\"\n",
    "\n",
    "    with open(md_path, \"w\", encoding=\"UTF-8\") as md_file:\n",
    "        md_file.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_path, md_path in [\n",
    "    (f\"{PDF_TR}/{pdf}\", f\"{MD_TR}/{pdf.split('.')[0]}.md\")\n",
    "    for pdf in sorted(os.listdir(PDF_TR))\n",
    "    if \".keepdir\" not in pdf\n",
    "]:\n",
    "    print(f\"[PROCESSING] {pdf_path}...\")\n",
    "\n",
    "    try:\n",
    "        pdf_to_md(pdf_path, md_path)\n",
    "    except Exception as err:\n",
    "        print(f\"[FAILED] {pdf_path}! Reason: {err}\")\n",
    "    else:\n",
    "        print(f\"[PROCESSED] {pdf_path}!\")\n",
    "\n",
    "    time.sleep(TIMEOUT_IN_SECONDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Summarization\n",
    "\n",
    "This stage focuses on generating concise summaries of the processed content. Due to the potential length of the combined initial chapter and digit-specific text, summarization is necessary to extract key concepts efficiently. The process involves combining the Markdown content from the chapter's introductory section and the specific digit's section. This combined text is then sent to the Google Gemini API, configured to produce a Turkish bulleted list summary highlighting the main ideas related to that digit. The resulting summary is saved to a new Markdown file, providing a condensed, easily digestible overview of the digit's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(initial_path: str, digit_path: str, summarization_path: str) -> None:\n",
    "    \"\"\"Generates a summary of Human Pin Code content by combining and processing two related text files.\n",
    "\n",
    "    Takes the initial chapter content and a specific digit's content from Markdown files,\n",
    "    combines them, and uses the Google Gemini API to generate a Turkish language summary\n",
    "    in bullet-point format.\n",
    "\n",
    "    Args:\n",
    "        initial_path: Path to the Markdown file containing the chapter's introductory content.\n",
    "        digit_path: Path to the Markdown file containing the specific digit's content.\n",
    "        summarization_path: Path where the generated summary will be saved.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If either initial_path or digit_path doesn't exist.\n",
    "        IOError: If there are issues reading input files or writing the output file.\n",
    "        AssertionError: If the Gemini API response text is None.\n",
    "        Exception: If the Gemini API request fails or returns an error.\n",
    "\n",
    "    Note:\n",
    "        - Uses UTF-8 encoding for all file operations\n",
    "        - Depends on the global client and summ_content_config for API interaction\n",
    "        - The summary is formatted according to the configuration in summ_content_config\n",
    "        - Output is saved in Markdown format with Turkish language content\n",
    "\n",
    "    Example:\n",
    "        >>> summarize(\"./tr/MDs/1_initial.md\", \"./tr/MDs/1_1.md\", \"./tr/Summarizations/1_1.md\")\n",
    "        # Summarizes initial and digit content and saves as \"./tr/Summarizations/1_1.md\"\n",
    "    \"\"\"\n",
    "    with (\n",
    "        open(initial_path, \"r\", encoding=\"UTF-8\") as initial_f,\n",
    "        open(digit_path, \"r\", encoding=\"UTF-8\") as digit_f,\n",
    "    ):\n",
    "        content = f\"{initial_f.read()}\\n\\n{digit_f.read()}\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-preview-05-20\",\n",
    "        contents=content,\n",
    "        config=summ_content_config,\n",
    "    )\n",
    "\n",
    "    assert response.text is not None, \"Response text should not be None\"\n",
    "\n",
    "    with open(summarization_path, \"w\", encoding=\"UTF-8\") as summ_file:\n",
    "        summ_file.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for md_path, initial_path, summ_path in [\n",
    "    (\n",
    "        f\"{MD_TR}/{md}\",\n",
    "        f\"{MD_TR}/{md.split('.')[0].split('_')[0]}_initial.md\",\n",
    "        f\"{SUMM_TR}/{md.split('.')[-2]}.md\",\n",
    "    )\n",
    "    for md in sorted(os.listdir(MD_TR))\n",
    "    if \"initial\" not in md\n",
    "]:\n",
    "    print(f\"[PROCESSING] {md_path}...\")\n",
    "\n",
    "    try:\n",
    "        summarize(initial_path, md_path, summ_path)\n",
    "    except Exception as err:\n",
    "        print(f\"[FAILED] {md_path}! Reason: {err}.\")\n",
    "    else:\n",
    "        print(f\"[PROCESSED] {md_path}!\")\n",
    "\n",
    "    time.sleep(TIMEOUT_IN_SECONDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
