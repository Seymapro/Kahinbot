{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline for [Human Pin Code](https://humanpincode.com/) by *Douglas Forbes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pymupdf\n",
    "import google.generativeai as genai\n",
    "\n",
    "import google.generativeai.types as gtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0: Preparations\n",
    "\n",
    "We need to initialize several constants and setup & define Google Gemini related stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DIR_TR = \"./tr\"\n",
    "PDF_TR = f\"{DIR_TR}/PDFs\"\n",
    "MD_TR = f\"{DIR_TR}/MDs\"\n",
    "SUMM_TR = f\"{DIR_TR}/Summarizations\"\n",
    "BOOK = \"./forbes.pdf\"\n",
    "\n",
    "TIMEOUT_IN_SECONDS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Google Gemini\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gemini(path, mime_type=None) -> gtypes.file_types.File:\n",
    "    \"\"\"Uploads the given file to Gemini.\n",
    "\n",
    "    See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
    "    \"\"\"\n",
    "    file = genai.upload_file(path, mime_type=mime_type)\n",
    "    print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_files_active(files) -> None:\n",
    "    \"\"\"Waits for the given files to be active.\n",
    "\n",
    "    Some files uploaded to the Gemini API need to be processed before they can be\n",
    "    used as prompt inputs. The status can be seen by querying the file's \"state\"\n",
    "    field.\n",
    "\n",
    "    This implementation uses a simple blocking polling loop. Production code\n",
    "    should probably employ a more sophisticated approach.\n",
    "    \"\"\"\n",
    "    print(\"Waiting for file processing...\")\n",
    "    for name in (file.name for file in files):\n",
    "        file = genai.get_file(name)\n",
    "        while file.state.name == \"PROCESSING\":\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(TIMEOUT_IN_SECONDS)\n",
    "            file = genai.get_file(name)\n",
    "        if file.state.name != \"ACTIVE\":\n",
    "            raise Exception(f\"File {file.name} failed to process\")\n",
    "    print(\"...all files ready\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Markdown model\n",
    "md_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-pro-exp-02-05\",\n",
    "    safety_settings=[\n",
    "        gtypes.SafetySettingDict(\n",
    "            category=gtypes.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "            threshold=gtypes.HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        gtypes.SafetySettingDict(\n",
    "            category=gtypes.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "            threshold=gtypes.HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        gtypes.SafetySettingDict(\n",
    "            category=gtypes.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "            threshold=gtypes.HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        gtypes.SafetySettingDict(\n",
    "            category=gtypes.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "            threshold=gtypes.HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "    ],\n",
    "    generation_config=gtypes.GenerationConfig(\n",
    "        max_output_tokens=8192,\n",
    "        temperature=1.0,\n",
    "        top_p=0.95,\n",
    "        top_k=64,\n",
    "        response_mime_type=\"text/plain\",\n",
    "    ),\n",
    "    system_instruction=\"\"\"You are a specialized Markdown converter designed to process and repair corrupted Turkish text files. Your task is to take potentially corrupted Turkish text, clean it, and convert it into well-formatted Markdown.  You should perform the following steps in order:\n",
    "\n",
    "1.  **Text Extraction and Preservation:**  Extract the complete text from the input.  Crucially, preserve the original character order and any unusual characters *even if they appear to be errors*.  Do not attempt to \"correct\" anything at this stage.\n",
    "\n",
    "2.  **De-hyphenation (Turkish-Specific):** Carefully de-hyphenate the raw text, paying close attention to Turkish hyphenation rules.  This involves:\n",
    "    *   Identifying hyphens at the end of lines.\n",
    "    *   Determining if the hyphen represents a true word break (requiring removal and joining of the word parts) or a hyphenated word (requiring the hyphen to be retained).  Use Turkish linguistic rules and context to make this determination. *Prioritize accurately joining words that were split across lines.*  Be conservative; if unsure, it's better to leave a hyphen than to incorrectly join unrelated words.\n",
    "\n",
    "3.  **Corruption Repair (Turkish-Specific):** This is the most complex step and requires a deep understanding of Turkish orthography and common OCR/scanning errors. Address the following types of corruption:\n",
    "    *   **Typos:** Correct common Turkish typographical errors, including incorrect characters, transpositions, and omissions. Use a Turkish spellchecker or language model (internally, if possible) to assist, but *prioritize corrections that are highly likely to be accurate*.  Avoid making speculative changes.\n",
    "    *   **Spacing Errors:**\n",
    "        *   **Missing Spaces:** Insert spaces between words where they are missing (e.g., \"kelimelerarasındaboşluk\").\n",
    "        *   **Extra Spaces:** Remove extraneous spaces within words (e.g., \"k e l i m e\") or between characters.\n",
    "        *   **Incorrect Spaces around Punctuation:** Ensure correct spacing around Turkish punctuation marks (periods, commas, question marks, etc.).\n",
    "    *   **Paragraph Reconstruction:**  Identify and correct incorrect paragraph breaks caused by page endings or scanning artifacts.  Use contextual clues (sentence structure, topic shifts) to determine true paragraph boundaries.  Combine fragments of sentences that were split across lines.\n",
    "    *   **Character Corruption:** Correct corrupted UTF-8 or other encoding issues. The goal is to correct the text to accurate Turkish spelling.\n",
    "\n",
    "4.  **Markdown Conversion:** Convert the cleaned and corrected Turkish text to Markdown, adhering to the following rules:\n",
    "    *   **Headings:**  Identify potential headings based on context and capitalization. Use appropriate Markdown heading levels (`#`, `##`, `###`, etc.).  Be conservative; if unsure, prefer a lower heading level or plain text.\n",
    "    *   **Lists:**  Identify and format bulleted or numbered lists. Look for common list indicators (e.g., numbers, bullets, dashes).\n",
    "    *   **Paragraphs:** Separate paragraphs with *two* newline characters (`\\n\\n`). This is crucial for proper Markdown rendering.\n",
    "    *   **Other Elements:** If you confidently identify other Markdown elements (e.g., bold, italics, blockquotes), format them appropriately. However, *prioritize accuracy over completeness*.  It's better to have plain text than incorrect Markdown.\n",
    "    * **Do not add any elements not supported in Markdown**\n",
    "\n",
    "5. **Output**\n",
    "    *   **Markdown Only:** Output *only* the resulting Markdown text. Do not include any explanations, comments, or additional information.\n",
    "    * **No additional changes:** Do not provide additional output.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the summarization model\n",
    "summ_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-pro-exp-02-05\",\n",
    "    safety_settings=[\n",
    "        gtypes.SafetySettingDict(\n",
    "            category=gtypes.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "            threshold=gtypes.HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        gtypes.SafetySettingDict(\n",
    "            category=gtypes.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "            threshold=gtypes.HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        gtypes.SafetySettingDict(\n",
    "            category=gtypes.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "            threshold=gtypes.HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        gtypes.SafetySettingDict(\n",
    "            category=gtypes.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "            threshold=gtypes.HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "    ],\n",
    "    generation_config=gtypes.GenerationConfig(\n",
    "        max_output_tokens=8192,\n",
    "        temperature=1.0,\n",
    "        top_p=0.95,\n",
    "        top_k=64,\n",
    "        response_mime_type=\"text/plain\",\n",
    "    ),\n",
    "    system_instruction=\"\"\"You are a specialist in summarizing personality typing systems, particularly those similar to and including Douglas Forbes' \"Human Design System\" (often referred to as the \"Human Pin Code,\" though this isn't the official name).  Your task is to create a comprehensive summary of the provided text (which will be pasted below this prompt).  The summary should be in the form of a bulleted list.\n",
    "\n",
    "**Specific Instructions:**\n",
    "\n",
    "1.  **Target Audience:** Assume the reader has *some* familiarity with the general concept of personality typing (e.g., Myers-Briggs, Enneagram) but may be new to Forbes' system or similar concepts.\n",
    "2.  **Focus:** Identify and summarize the *key concepts, principles, and terminology* presented in the text.  Don't get bogged down in minor details; prioritize the core ideas.  If the text describes specific types, profiles, or categories, clearly outline their defining characteristics.\n",
    "3.  **Language:**  The summary must be written in **Turkish**.\n",
    "4.  **Format:** Use Markdown for the bulleted list. Each bullet point should be concise but informative.  Use nested bullet points (indentation) to show hierarchical relationships between concepts where appropriate.  For example, if a main concept has several sub-components, list the main concept as a top-level bullet and the sub-components as indented bullets beneath it.\n",
    "5.  **Comprehensiveness:** While concise, the summary should be comprehensive enough that someone reading it would gain a solid understanding of the main ideas presented in the original text. Avoid overly simplistic or vague summaries.\n",
    "6.  **Objectivity:** Maintain a neutral and objective tone.  Do not express personal opinions about the validity or usefulness of the system being described.  Present the information as it is presented in the text.\n",
    "7.  **Terminology:** Pay close attention to any specialized terminology used in the text.  If the Turkish translation of a term isn't immediately obvious, provide the English term in parentheses after the Turkish term the *first* time it appears.  (e.g., \"Enerji Tipi (Energy Type)\")\n",
    "8. **Contextualization (if applicable):** If the provided text refers to other personality systems or authors, briefly note these connections in the summary *if they are essential to understanding the main points*.\n",
    "\n",
    "**Example Structure (Markdown - Turkish):**\n",
    "\n",
    "```markdown\n",
    "- **Ana Kavram 1:** Kısa açıklama.\n",
    "    - Alt Kavram 1.1: Daha detaylı açıklama.\n",
    "    - Alt Kavram 1.2: Daha detaylı açıklama.\n",
    "- **Ana Kavram 2:** Kısa açıklama (İngilizce Terim).\n",
    "    - Alt Kavram 2.1: Daha detaylı açıklama.\n",
    "- **Ana Kavram 3:** ...\n",
    "```\n",
    "\n",
    "Do not provide additional output.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Partition the book by its chapters and digits\n",
    "\n",
    "The book \"Human Pin Code\" is structured with several chapters, each chapter containing \"pin code\" digits and their traits. Here, we map these chapters and digits to their page ranges in the book and we partition based on these page ranges.\n",
    "\n",
    "Partitioning is important to provide the LLMs only the related information in order to reduce the chances of hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGITS_TO_PAGE_RANGE = {\n",
    "    1: {\n",
    "        \"initial\": (59, 61),\n",
    "        1: (61, 65),\n",
    "        2: (65, 67),\n",
    "        3: (67, 69),\n",
    "        4: (69, 71),\n",
    "        5: (71, 73),\n",
    "        6: (73, 76),\n",
    "        7: (76, 78),\n",
    "        8: (78, 80),\n",
    "        9: (80, 83),\n",
    "    },\n",
    "    2: {\n",
    "        \"initial\": (85, 87),\n",
    "        1: (87, 89),\n",
    "        2: (89, 91),\n",
    "        3: (91, 93),\n",
    "        4: (93, 96),\n",
    "        5: (98, 101),\n",
    "        6: (101, 103),\n",
    "        7: (103, 105),\n",
    "        8: (105, 107),\n",
    "        9: (107, 109),\n",
    "    },\n",
    "    3: {\n",
    "        \"initial\": (111, 112),\n",
    "        1: (112, 115),\n",
    "        2: (115, 117),\n",
    "        3: (117, 119),\n",
    "        4: (119, 122),\n",
    "        5: (122, 124),\n",
    "        6: (124, 126),\n",
    "        7: (126, 129),\n",
    "        8: (129, 131),\n",
    "        9: (131, 133),\n",
    "    },\n",
    "    4: {\n",
    "        \"initial\": (135, 136),\n",
    "        1: (136, 138),\n",
    "        2: (138, 140),\n",
    "        3: (140, 142),\n",
    "        4: (142, 144),\n",
    "        5: (144, 146),\n",
    "        6: (146, 148),\n",
    "        7: (148, 150),\n",
    "        8: (150, 152),\n",
    "        9: (152, 155),\n",
    "    },\n",
    "    5: {\n",
    "        \"initial\": (157, 159),\n",
    "        1: (159, 161),\n",
    "        2: (161, 163),\n",
    "        3: (163, 165),\n",
    "        4: (165, 167),\n",
    "        5: (167, 169),\n",
    "        6: (169, 171),\n",
    "        7: (171, 173),\n",
    "        8: (173, 175),\n",
    "        9: (175, 177),\n",
    "    },\n",
    "    6: {\n",
    "        \"initial\": (180, 182),\n",
    "        1: (182, 184),\n",
    "        2: (184, 186),\n",
    "        3: (186, 188),\n",
    "        4: (188, 191),\n",
    "        5: (191, 193),\n",
    "        6: (193, 195),\n",
    "        7: (195, 198),\n",
    "        8: (198, 201),\n",
    "        9: (201, 203),\n",
    "    },\n",
    "    7: {\n",
    "        \"initial\": (204, 205),\n",
    "        1: (205, 207),\n",
    "        2: (207, 209),\n",
    "        3: (209, 211),\n",
    "        4: (211, 213),\n",
    "        5: (213, 214),\n",
    "        6: (214, 216),\n",
    "        7: (216, 218),\n",
    "        8: (218, 220),\n",
    "        9: (220, 222),\n",
    "    },\n",
    "    8: {\n",
    "        \"initial\": (224, 226),\n",
    "        1: (226, 228),\n",
    "        2: (228, 230),\n",
    "        3: (230, 232),\n",
    "        4: (232, 234),\n",
    "        5: (234, 236),\n",
    "        6: (236, 238),\n",
    "        7: (238, 240),\n",
    "        8: (240, 242),\n",
    "        9: (242, 244),\n",
    "    },\n",
    "    9: {\n",
    "        \"initial\": (246, 247),\n",
    "        1: (247, 248),\n",
    "        2: (248, 249),\n",
    "        3: (249, 250),\n",
    "        4: (250, 251),\n",
    "        5: (251, 252),\n",
    "        6: (252, 253),\n",
    "        7: (253, 254),\n",
    "        8: (254, 255),\n",
    "        9: (255, 256),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymupdf.open(BOOK) as forbes_book:\n",
    "    for place, digits in DIGITS_TO_PAGE_RANGE.items():\n",
    "        for digit, (start, end) in digits.items():\n",
    "            with pymupdf.open() as part_pdf:\n",
    "                part_pdf.insert_pdf(forbes_book, from_page=start, to_page=end - 1)\n",
    "                part_pdf.save(f\"{PDF_TR}/{place}_{digit}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Convert PDF partitions to Markdown files\n",
    "\n",
    "Working with raw textual data is almost always better than working with binary data formats like PDF. That is why we're converting each partition to the Markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_md(pdf_path: str, md_path: str) -> None:\n",
    "    files = [upload_to_gemini(pdf_path, mime_type=\"application/pdf\")]\n",
    "    wait_for_files_active(files)\n",
    "\n",
    "    chat_session = md_model.start_chat(history=[{\"role\": \"user\", \"parts\": files}])\n",
    "    response = chat_session.send_message(\"Convert this PDF file to Markdown.\")\n",
    "\n",
    "    files[0].delete()\n",
    "\n",
    "    with open(md_path, \"w\", encoding=\"UTF-8\") as md_f:\n",
    "        md_f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_path, md_path in [\n",
    "    (f\"{PDF_TR}/{pdf}\", f\"{MD_TR}/{pdf.split('.')[0]}.md\")\n",
    "    for pdf in sorted(os.listdir(PDF_TR))\n",
    "]:\n",
    "    print(f\"[PROCESSING] {pdf_path}...\")\n",
    "    try:\n",
    "        pdf_to_md(pdf_path, md_path)\n",
    "    except Exception as err:\n",
    "        print(f\"[FAILED] {pdf_path}! Reason: {err}\")\n",
    "    else:\n",
    "        print(f\"[PROCESSED] {pdf_path}!\")\n",
    "\n",
    "    time.sleep(TIMEOUT_IN_SECONDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Summarization\n",
    "\n",
    "Apparently the full text is too long -- so we summarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(initial_path: str, digit_path: str, summarization_path: str) -> None:\n",
    "    with (\n",
    "        open(initial_path, \"r\", encoding=\"UTF-8\") as initial_f,\n",
    "        open(digit_path, \"r\", encoding=\"UTF-8\") as digit_f,\n",
    "    ):\n",
    "        content = f\"{initial_f.read()}\\n\\n{digit_f.read()}\"\n",
    "\n",
    "    chat_session = summ_model.start_chat()\n",
    "    response = chat_session.send_message(content)\n",
    "\n",
    "    with open(summarization_path, \"w\", encoding=\"UTF-8\") as summ_f:\n",
    "        summ_f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for md_path, initial_path, summ_path in [\n",
    "    (\n",
    "        f\"{MD_TR}/{md}\",\n",
    "        f\"{MD_TR}/{md.split('.')[0].split('_')[0]}_initial.md\",\n",
    "        f\"{SUMM_TR}/{md.split('.')[-2]}.md\",\n",
    "    )\n",
    "    for md in sorted(os.listdir(MD_TR))\n",
    "    if \"initial\" not in md\n",
    "]:\n",
    "    print(f\"[PROCESSING] {md_path}...\")\n",
    "    try:\n",
    "        summarize(initial_path, md_path, summ_path)\n",
    "    except Exception as err:\n",
    "        print(f\"[FAILED] {md_path}! Reason: {err}.\")\n",
    "    else:\n",
    "        print(f\"[PROCESSED] {md_path}!\")\n",
    "\n",
    "    time.sleep(TIMEOUT_IN_SECONDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
